---
title: "Concurrent Validity"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette_Validity}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Illustration of Concurrent Validity

This is a pretty easy one, just run some correlations. I think the scatter plot of the correlations is well-received, worth including that. 

```{r output_dir, echo = F}
print.dir = "C:/Users/ciaconangelo/OneDrive - OPEN Health/Documents/misc_R_table_output"
```


## Generate data
```{r generate}
  set.seed(5122021)

library(COA34)
sim.out <- COA34::sim_pro_dat(N=1e3,
                        polychor.value = 0.4,
                        corr = 'ar1',
                        cor.value = 0.8,
                        var.values = c(5))

dat <- sim.out$dat

# You already have the PGIS_bl and PGIS_delta in the generated data,
# you wouldn't have that in a real dataset, so drop that first
dat <- dat[, !(colnames(dat) %in% c('PGIS_bl', 'PGIS_delta'))]
# This makes the rest of this more realistic

```

## Implement drop-out

```{r missing}
dat <- COA34::dropout(dat = dat,
               type_dropout  = c('mcar', 'mar', 'mnar'),
               prop.miss = 0.5,
               stochastic.component = 0.2)

```


## Managing Variables
I can't overemphasize how important it is to keep an eye on your variables. 
The functions will do all the work, you just have to carefully manage your data. 

```{r data_mgmt}
str(dat)
# PGIS is ordinal; transform it for the purposes of correct correlation
# Leave it numeric to compute the PGIS_delta for the change scores later
dat.cor <- dat
dat.cor$PGIS <-
  factor(dat.cor$PGIS,
         levels = c(0, 1, 2, 3, 4),
         labels = c('None', 'Mild', 'Moderate', 'Severe', 'Very Severe'))
table(dat.cor$PGIS, useNA = 'always')
xtabs(~ dat.cor$PGIS + dat$PGIS)

# Validator Variables 1 and 5 are supposed to be
# ordered categorical variables
dat.cor$Val_1 <- factor(dat.cor$Val_1)
table(dat.cor$Val_1, useNA = 'always')
# only collected at baseline, hence the NAs

dat.cor$Val_5 <- factor(dat.cor$Val_5)
table(dat.cor$Val_5, useNA = 'always')
# Only collected at baseline, hence the NAs

# Check data:
str(dat.cor)
# 5 validator variables (Val_1, Val_2...Val_5)
# 4 PRO scores

```

## Compute Correlations of Multiple Scores

Use the function to create a large table of the correlations you need. 

```{r val1}
out <- COA34::compute_validity(dat = dat.cor,
                               time.var = 'Time',
                               PRO.score = c('Y_comp', 'Y_mcar', 'Y_mar', 'Y_mnar'),
                               val.var = c('PGIS', paste0('Val_', 1:5))
                               )

# Compare output to generating values:
sim.out$out.val$cor.mat.ref

library(R2Word)

R2Word::dump_df_mat_to_file(out = out,
                            decimals = c(0, 2), 
                            table.title = 'Correlations - Vignette Illustration', 
                            table.footnote = '**All data simulated',
                            file.name = 'val_vig_t1', 
                            print.dir = print.dir)
```


## Scatterplots of Correlations

Let's compute for a single score and create a scatterplot. This visualization has been well-received, make use of it. 
```{r val2}
out1 <- COA34::compute_validity(dat = dat.cor,
                               time.var = 'Time',
                               PRO.score = c('Y_comp'),
                               val.var = c('PGIS', paste0('Val_', 1:5))
                               )


```

We have the output values, let's make the scatterplot:

```{r val3}
# Scatterplot of Correlations:
library(ggplot2)
p1 <- ggplot(out1, aes(x = `Validator Variable`, y = Correlation)) +
  geom_point() +
  theme_minimal() +
  theme(axis.text.x=element_blank()) +
  scale_y_continuous(lim = c(0,1), breaks = seq(0, 1, by = 0.1))

library(ggrepel)
p2 <- p1 + ggrepel::geom_text_repel(aes(label = `Validator Variable`),
              size = 3.5)
p2

# How to customize the labels
out1$label <-
  ifelse(out1$`Validator Variable` == 'PGIS', 'PGIS anchor',
         ifelse(out1$`Validator Variable` == 'Val_1', 'PGIC',
                ifelse(out1$`Validator Variable` == 'Val_2', 'SF-36', 
                       ifelse(out1$`Validator Variable` == 'Val_3', 'EQ-5D',
                              ifelse(out1$`Validator Variable` == 'Val_4', 'NSCLC-SAQ',
                                     ifelse(out1$`Validator Variable` == 'Val_5', 'SF-36, Physical Functioning',
                                            NA))))))

library(ggrepel)
p3 <- p1 + ggrepel::geom_text_repel(data = out1, aes(label = `label`),
              size = 3.5)
p3

```


## Note on timepoints
The compute_validity() function will automatically select the baseline timepoint. 
If you want to use a different timepoint, you'll have to pass a dataframe with only that data! Quick example:

```{r time}
out2 <- COA34::compute_validity(dat = dat.cor[dat.cor$Time == 'Time_4', ],
                               time.var = 'Time',
                               PRO.score = c('Y_comp', 'Y_mcar', 'Y_mar', 'Y_mnar'),
                               val.var = c('PGIS')
                               )

out2
```
